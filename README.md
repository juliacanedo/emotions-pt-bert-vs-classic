# ğŸ­ Emotions-PT â€” BERT vs. Classic ML para ClassificaÃ§Ã£o de EmoÃ§Ãµes em PortuguÃªs  
**Multilabel Emotion Classification â€¢ BERTimbau + Logistic Regression â€¢ SCut Threshold Optimization**

<div align="center">

[![Python](https://img.shields.io/badge/Python-3.10+-blue?style=for-the-badge&logo=python)]()
[![PyTorch](https://img.shields.io/badge/PyTorch-2.x-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)]()
[![Transformers](https://img.shields.io/badge/HuggingFace-Transformers-yellow?style=for-the-badge&logo=huggingface)]()
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)]()

</div>

---

## ğŸ“ Sobre o Projeto

Este repositÃ³rio implementa um pipeline **completo e reprodutÃ­vel** para classificaÃ§Ã£o multilabel de emoÃ§Ãµes em portuguÃªs, comparando o desempenho de um modelo BERTimbau e um algoritmo ClÃ¡ssico (TF-IDF + RegressÃ£o LogÃ­stica).

### ğŸ”¥ Modelos BERT (HuggingFace)
- BERTimbau Base / Large  
- Fine-tuning com **Class-Balanced Loss (CB-Loss)**  
- AvaliaÃ§Ã£o completa (F1-micro/macro, mAP, ECE)  
- **CalibraÃ§Ã£o + OtimizaÃ§Ã£o de thresholds (SCut / FÎ²)**  

### âš™ï¸ Baseline ClÃ¡ssico (TF-IDF + Logistic Regression)
- ExtraÃ§Ã£o hÃ­brida TF-IDF (words + char-ngrams)
- One-vs-Rest Logistic Regression
- OtimizaÃ§Ã£o de thresholds classe a classe

### ğŸ¯ Objetivo
Comparar abordagens clÃ¡ssicas vs deep learning no dataset **GoEmotions-PT (28 emoÃ§Ãµes)** traduzido automaticamente e limpo.

---

## ğŸ“‚ Estrutura do RepositÃ³rio

```txt
.
â”œâ”€â”€ configs/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/ * Arquivos originais do dataset GoEmotions-PTBR  
â”‚   â”‚       Fonte: https://huggingface.co/datasets/antoniomenezes/go_emotions_ptbr/tree/main 
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ retunes/
â”‚   â””â”€â”€ models/
â”œâ”€â”€ notebooks/ # AnÃ¡lise do projeto + Interpretabilidade + script para gerar imagens
â”œâ”€â”€ scripts/
â”œâ”€â”€ src/
â”‚    â”œâ”€â”€ features/
â”‚    â””â”€â”€ utils/
â”œâ”€â”€ run_pipeline.ps1
â”œâ”€â”€ run_pipeline.sh
â”œâ”€â”€ requirements_base.txt # Bibliotecas base
â”œâ”€â”€ requirements_cpu.txt # PadrÃ£o de instalaÃ§Ã£o para CPU
â”œâ”€â”€ requirements_gpu.txt # PadrÃ£o de instalaÃ§Ã£o para GPU (*recomendado*)
â””â”€â”€ README.md
```

---

## ğŸš€ Pipeline Completo (One-Command)

### Windows
```powershell
.\run_pipeline.ps1
```

### Linux
```bash
./run_pipeline.sh
```

O pipeline executa:

1. CriaÃ§Ã£o/remoÃ§Ã£o do venv  
2. Checagem de GPU  
3. InstalaÃ§Ã£o CPU/GPU  
4. Preprocessamento  
5. EDA  
6. Treino BERT  
7. Treino ClÃ¡ssico  
8. SCut + CalibraÃ§Ã£o  
9. InicializaÃ§Ã£o do modelo de classificaÃ§Ã£o com melhor BERT Treinado 

---

## ğŸ’» InstalaÃ§Ã£o Manual

Clone o repositÃ³rio:

```bash
git clone https://github.com/seu-user/emotions-pt-bert-vs-classic.git
cd emotions-pt-bert-vs-classic
```

Criar venv:

```bash
python -m venv venv
source venv/bin/activate      # Linux
venv\Scripts\Activate.ps1   # Windows
```

Instalar dependÃªncias GPU:

```bash
pip install -r requirements_gpu.txt
```

Ou CPU:

```bash
pip install -r requirements_cpu.txt
```

---

## Treinar BERT

```bash
python scripts/run_bert.py     --cfg configs/base.yaml configs/data.yaml configs/bert.yaml
```

---

## Treinar ClÃ¡ssico

```bash
python scripts/run_classic.py     --cfg configs/base.yaml configs/data.yaml configs/classic.yaml
```

---

## OtimizaÃ§Ã£o SCut / FÎ²

```bash
python scripts/run_retune_scut.py
```

---

## PrediÃ§Ã£o

```bash
python scripts/predict_bert_calibrated.py --text "Estou muito feliz hoje!"
```

---

## LicenÃ§a

Este projeto usa licenÃ§a **MIT**.

---